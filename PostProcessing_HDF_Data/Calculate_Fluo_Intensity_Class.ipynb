{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to calculate the total fluorescence intensity of area covered by nucleus in raw fluorescence channel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.spatial as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scipy.ndimage import label, find_objects\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from Movie_Analysis_Pipeline.Single_Movie_Processing.Server_Movies_Paths import Get_MDCK_Movies_Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fluo_Signal_Intensity(object):\n",
    "\n",
    "    def __init__(self, hdf5_file):\n",
    "        \"\"\" Open & read data from chosen HDF5 file. TODO: This class only processes GFP cells. Deal with it!\n",
    "            :param hdf5_file (str):                 absolute directory to file: .../HDF/segmented.hdf5\n",
    "        \"\"\"\n",
    "\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.hdf5_file_to_read = h5py.File(hdf5_file, 'r')\n",
    "        self.movie_length = len(self.hdf5_file_to_read[\"objects\"][\"obj_type_1\"][\"map\"])\n",
    "        self.channels = len(list(self.hdf5_file_to_read.values())[0])\n",
    "        \n",
    "        GFP_length = len(self.hdf5_file_to_read[\"objects\"][\"obj_type_1\"][\"coords\"])\n",
    "\n",
    "        if \"obj_type_1\" not in list(self.hdf5_file_to_read[\"objects\"]):\n",
    "            raise ValueError(\"GFP channel not detected in the HDF5 file.\")\n",
    "\n",
    "        self.position = hdf5_file.split(\"/pos\")[1].split(\"/\")[0]\n",
    "        self.data_date = hdf5_file.split(\"/pos{}\".format(self.position))[0][-6:]\n",
    "        \n",
    "        self.raw_movie = \"/Volumes/lowegrp/Data/Kristina/MDCK_WT_Pure/17_{}_{}/pos{}/GFP_pos8.tif\" \\\n",
    "                            .format(self.data_date[2:4], self.data_date[4:6], self.position)\n",
    "        \n",
    "        self.raw_image_sequence = io.imread(movie_GFP)\n",
    "        \n",
    "        if not self.data_date.startswith(\"AB\") and not self.data_date.startswith(\"GV\"):\n",
    "            raise AttributeError(\"Wrong HDF file initiation on position <{}> or data_date <{}>.\".format(self.position, self.data_date))\n",
    "\n",
    "        # Vectors to return:\n",
    "        self.nucleus = [0 for _ in range(GFP_length)]\n",
    "        self.fsignal = [0 for _ in range(GFP_length)]\n",
    "\n",
    "\n",
    "    def Extract_Cell_Coords(self, frame):\n",
    "        \"\"\" Extract the GFP and RFP cell coordinates, remembering the indexes of these cells.\n",
    "\n",
    "        :param      frame           (int)\n",
    "        :return:    cell_coords     (numpy.ndarray)     [[x_coord, y_coord] [x_coord, y_coord] ... ]\n",
    "                    cell_map        (numpy.ndarray)     [[0 88] [0 20]] -> indices of GFP & RFP cells per frame\n",
    "        \"\"\"\n",
    "\n",
    "        cell_coords = []\n",
    "        cell_map = []\n",
    "        \n",
    "        for channel in range(1, self.channels + 1):\n",
    "            map = self.hdf5_file_to_read[\"objects\"][\"obj_type_{}\".format(channel)][\"map\"][frame]\n",
    "            cell_map.append(map)\n",
    "            for cell in range(map[0], map[1]):\n",
    "                cell_data = self.hdf5_file_to_read[\"objects\"][\"obj_type_{}\".format(channel)][\"coords\"][cell]\n",
    "                cell_coords.append([cell_data[1], cell_data[2]])\n",
    "        \n",
    "        return np.array(cell_coords), np.array(cell_map)\n",
    "\n",
    "\n",
    "    def Calculate_Nuclei_Sizes(self, frame, show=False):\n",
    "        \"\"\" Process the respective binary mask (U-Net output with segmented labels)\n",
    "            to extract the pixel values of the image into 2D matrix to return.\n",
    "\n",
    "            1.) Import the 'segmentation' binary mask image & label the pixel values of individual objects.\n",
    "            2.) Allocate the nuclei centroids from HDF file to each uniquely labelled blob in the binary mask.\n",
    "            3.) Count the occurence of the label in the processed binary mask & store it's row & column indices.\n",
    "            4.) Access the corresponding pixels in the raw fluorescence image to calculate average signal intensity.\n",
    "        \"\"\"\n",
    "\n",
    "        cell_coords, cell_map = self.Extract_Cell_Coords(frame=frame)\n",
    "        pixels = self.hdf5_file_to_read[\"segmentation\"][\"images\"][frame]\n",
    "\n",
    "        # Enumerate different objects in the map with unique label & find those objects in the image:\n",
    "        object_labels, num_features = label(input=pixels)\n",
    "        found_objects = find_objects(object_labels)\n",
    "\n",
    "        if num_features != len(found_objects):\n",
    "            raise ValueError(\"Warning, number of labelled objects & the objects found with unique label are not equal!\")\n",
    "\n",
    "        # Visualise the binary map & labelled map:\n",
    "        if show is True:\n",
    "            plt.imshow(X=pixels)  # plots a 2D array straight ahead!\n",
    "            plt.title(\"Raw Segmented Binary Mask at frame #{}\".format(frame))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            plt.imshow(X=object_labels)  # plots a 2D array straight ahead!\n",
    "            plt.title(\"Labelled Segmented Binary Mask at frame #{}\".format(frame))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # Match coords to its unique label & sum the appearance of the label in the slice:\n",
    "        nuclei_size = []\n",
    "        for coords in cell_coords:\n",
    "            x, y = int(math.floor(coords[0])), int(math.floor(coords[1]))\n",
    "            pixel_label = object_labels[x][y]\n",
    "            image_slice = object_labels[found_objects[pixel_label - 1]]\n",
    "            nucleus_size = sum([list(row).count(pixel_label) for row in image_slice])\n",
    "            nuclei_size.append(nucleus_size)\n",
    "\n",
    "        # Append these sizes into the final array:\n",
    "        self.nucleus[cell_map[0][0]:cell_map[0][1]] = np.array(nuclei_size, dtype=np.uint8)\n",
    "\n",
    "        #print (object_labels)\n",
    "        #print (found_objects)\n",
    "        \n",
    "        return nuclei_size, object_labels, found_objects\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def Calculate_Fluo_Intensity(self, frame, show=False):\n",
    "        \"\"\" Calculate the average fluorescence intensity of the nucleus based on the pixel value readouts\n",
    "            from areas superimposed by uniquely labelled binary mask areas by summing them up & averaging.\n",
    "\n",
    "            :param! raw_images  (str)   ->      absolute directory to folder:\n",
    "\n",
    "                    Anna's movies:      e.g./Volumes/lowegrp/Data/Kristina/MDCK_WT_Pure/17_07_31/pos8/...\n",
    "                                            which contains STACK TIFFs: 'BF_pos8.tif', 'GFP_pos8.tif', 'RFP_pos8.tif'\n",
    "                    Giulia's movies:    e.g./Volumes/lowegrp/Data/Guilia/GV0800/pos0/Pos0_aligned/\n",
    "                                            which contains original BF, GFP & RFP images: e.g.\n",
    "                                            'img_channel001_position013_time000001104_z000.tif'\n",
    "        \"\"\"\n",
    "\n",
    "        cell_coords, cell_map = self.Extract_Cell_Coords(frame=frame)\n",
    "        nuclei_size, object_labels, found_objects = self.Calculate_Nuclei_Sizes(frame=frame)\n",
    "        fluo_signal_int = [0 for _ in range(len(nuclei_size))]\n",
    "\n",
    "        if self.data_date.startswith(\"AB\"):\n",
    "            img = self.raw_image_sequence[frame]\n",
    "            print (\"Type: {}\".format(type(img)))\n",
    "            print (\"Image: {}\".format(img))\n",
    "            \n",
    "        \n",
    "        elif self.data_date.startswith(\"GV\"):\n",
    "            img = \"/Volumes/lowegrp/Data/Giulia/{}/pos{}/Pos{}_aligned/img_channel001_position{}_time00000{}_z000.tif\"\\\n",
    "                   .format(self.data_date, self.position, self.position, self.position.zfill(3), str(frame).zfill(4))\n",
    "            print (\"Image: {}\".format(img))\n",
    "        \n",
    "            if not os.path.isfile(img):\n",
    "                return np.array(fluo_signal_int, dtype=np.float64)\n",
    "\n",
    "            # Process the full-sized image:\n",
    "            image = Image.open(img).convert('L')          # converts the image to 8-bit grayscale\n",
    "            img_w, img_h = image.size                     # stores image dimensions\n",
    "\n",
    "            # Define center & crop image accordingly:\n",
    "            new_w, new_h = 1600, 1200\n",
    "            if img_w != new_w or img_h != new_h:\n",
    "                left = (img_w - new_w) / 2\n",
    "                top = (img_h - new_h) / 2\n",
    "                right = (img_w + new_w) / 2\n",
    "                bottom = (img_h + new_h) / 2\n",
    "                image = image.crop((left, top, right, bottom))\n",
    "\n",
    "            data = np.array(image.getdata())              # converts data to single pixel list; len = 1600 x 1200\n",
    "            pixels = [data[offset:offset + img_w] for offset in range(0, img_w * img_h, img_w)]\n",
    "                # converts data to 2D list (list of 'numpy.ndarray' of 'numpy.int64'); access via pixels[row][col]\n",
    "\n",
    "            # Visualise the image:\n",
    "            if show is True:\n",
    "                plt.imshow(X=pixels)\n",
    "                plt.title(\"GFP image ({} x {} pixels) at frame #{}\".format(img_w, img_h, frame))\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "\n",
    "        # Check whether the dimensions of your uniquely labelled image & your raw fluo image are the same:\n",
    "        fluo_raw_im = np.array(img)     # convert 'PIL.Image.Image' to 'numpy.ndarray'\n",
    "\n",
    "        if object_labels.shape[0] != fluo_raw_im.shape[0] or object_labels.shape[1] != fluo_raw_im.shape[1]:\n",
    "            raise ValueError(\"Dimensions of uniquely labelled image <{}> & raw fluorescence image <{}> \"\n",
    "                             \"are not matching! -> It should be <{}>\".format(object_labels.shape,\n",
    "                                                             fluo_raw_im.shape, (new_h, new_w)))\n",
    "\n",
    "        # Superimpose the segmented masks with unique labels to the raw fluorescence readout images:\n",
    "        if len(cell_coords) != len(nuclei_size):\n",
    "            raise ValueError(\"Not every cell nucleus had had it's size calculated.\")\n",
    "\n",
    "        for enum, (coords, size) in enumerate(zip(cell_coords, nuclei_size)):\n",
    "\n",
    "            if size == 0:\n",
    "                fluo_signal_int[enum] = 0.0\n",
    "\n",
    "            else:\n",
    "                x, y = int(math.floor(coords[0])), int(math.floor(coords[1]))\n",
    "                pixel_label = object_labels[x][y]\n",
    "                found_loc = found_objects[pixel_label - 1]\n",
    "                image_slice_mask = object_labels[found_loc]\n",
    "                image_slice_fluo = fluo_raw_im[found_loc]\n",
    "\n",
    "                fluo_value_sum = 0\n",
    "                for row_mask, row_fluo in zip(image_slice_mask, image_slice_fluo):\n",
    "                    for label_pixel, raw_pixel in zip(row_mask, row_fluo):\n",
    "                        if label_pixel == pixel_label:\n",
    "                            fluo_value_sum += raw_pixel\n",
    "\n",
    "                fluo_signal_int[enum] = float(float(fluo_value_sum) / float(size))\n",
    "\n",
    "        self.fsignal[cell_map[0][0]:cell_map[0][1]] = np.array(fluo_signal_int, dtype=np.float64)\n",
    "        return np.array(fluo_signal_int, dtype=np.float64)\n",
    "            \n",
    "            \n",
    "    # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def Process_Whole_Movie(self):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        #for frame in tqdm(range(0, self.movie_length)):\n",
    "        for frame in tqdm(range(0, 10)):\n",
    "\n",
    "            if frame % 100 == 0:\n",
    "                print(\"\\nCalculating for frame #{} out of {} frames...\".format(frame, self.movie_length))\n",
    "\n",
    "            self.Calculate_Fluo_Intensity(frame=frame)\n",
    "\n",
    "        if self.hdf5_file_to_read.__bool__():\n",
    "            self.hdf5_file_to_read.close()\n",
    "\n",
    "        return self.fsignal\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def Append_To_HDF(self, local_density=False, nucleus_size=False, fluo_signal=False):\n",
    "\n",
    "        density, nucleus, fsignal = self.Process_Whole_Movie(local_density=local_density,\n",
    "                                                             nucleus_size=nucleus_size,\n",
    "                                                             fluo_signal=fluo_signal)\n",
    "\n",
    "        with h5py.File(self.hdf5_file, 'a') as f:\n",
    "            if \"density\" in list(f[\"objects\"][\"obj_type_1\"]):\n",
    "                del f[\"objects\"][\"obj_type_1\"][\"density\"]\n",
    "\n",
    "            if \"local_density\" in list(f[\"objects\"][\"obj_type_1\"]):\n",
    "                del f[\"objects\"][\"obj_type_1\"][\"local_density\"]\n",
    "\n",
    "            grp_d = f[\"objects\"][\"obj_type_1\"]\n",
    "            grp_d.create_dataset(name=\"local_density\", data=density)\n",
    "\n",
    "            if \"nucleus_size\" in list(f[\"objects\"][\"obj_type_1\"]):\n",
    "                del f[\"objects\"][\"obj_type_1\"][\"nucleus_size\"]\n",
    "\n",
    "            grp_n = f[\"objects\"][\"obj_type_1\"]\n",
    "            grp_n.create_dataset(name=\"nucleus_size\", data=nucleus)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __exit__(self):\n",
    "        self.hdf5_file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating for frame #0 out of 1793 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:00<00:03,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[224 150   8 ...   4   3   2]\n",
      " [  6   6   6 ...   3   3   4]\n",
      " [  5   7   6 ...   3   3   2]\n",
      " ...\n",
      " [  4   4   5 ...   3   2   3]\n",
      " [  4   5   6 ...   3   3   4]\n",
      " [  5   5   4 ...   4   2   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:00<00:03,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[142 219 136 ...   3   3   2]\n",
      " [  8   6   6 ...   4   3   2]\n",
      " [  6   7   6 ...   3   3   4]\n",
      " ...\n",
      " [  5   6   4 ...   4   3   2]\n",
      " [  4   5   6 ...   3   3   3]\n",
      " [  6   4   5 ...   2   2   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:01<00:02,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[ 60 113 135 ...   3   2   3]\n",
      " [  6   5   6 ...   3   2   3]\n",
      " [  6   7   6 ...   3   3   3]\n",
      " ...\n",
      " [  5   5   5 ...   3   2   3]\n",
      " [  5   5   5 ...   3   3   3]\n",
      " [  6   6   3 ...   3   2   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:01<00:02,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[234  29   6 ...   4   3   3]\n",
      " [  7   5   7 ...   3   3   2]\n",
      " [  7   6   6 ...   4   3   2]\n",
      " ...\n",
      " [  4   4   5 ...   3   2   2]\n",
      " [  5   5   6 ...   3   4   3]\n",
      " [  5   5   6 ...   3   2   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:01<00:01,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[152 147  27 ...   4   2   4]\n",
      " [  6   6   7 ...   3   2   3]\n",
      " [  5   7   5 ...   4   4   3]\n",
      " ...\n",
      " [  6   7   7 ...   2   4   3]\n",
      " [  5   5   6 ...   3   3   3]\n",
      " [  5   7   5 ...   3   3   4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:02<00:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[ 70  38 136 ...   3   4   3]\n",
      " [  6   6   6 ...   3   5   3]\n",
      " [  6   7   6 ...   3   3   2]\n",
      " ...\n",
      " [  5   5   6 ...   2   3   2]\n",
      " [  4   5   5 ...   2   3   2]\n",
      " [  6   5   5 ...   1   3   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:02<00:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[243  98  35 ...   5   4   3]\n",
      " [  6   6   6 ...   3   2   3]\n",
      " [  6   5   5 ...   5   4   4]\n",
      " ...\n",
      " [  6   5   4 ...   4   3   2]\n",
      " [  4   4   5 ...   2   1   1]\n",
      " [  5   5   5 ...   3   2   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:02<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[160  73  48 ...   2   3   4]\n",
      " [  7   7   6 ...   3   4   3]\n",
      " [  7   7   6 ...   4   3   4]\n",
      " ...\n",
      " [  5   4   4 ...   2   2   2]\n",
      " [  5   4   5 ...   2   3   1]\n",
      " [  5   5   4 ...   3   2   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[ 77 146  48 ...   3   3   2]\n",
      " [  7   7   6 ...   3   4   3]\n",
      " [  5   6   6 ...   4   3   2]\n",
      " ...\n",
      " [  4   5   4 ...   4   2   3]\n",
      " [  4   4   5 ...   2   2   2]\n",
      " [  5   4   5 ...   4   3   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Image: [[251  39 171 ...   3   4   4]\n",
      " [  6   7   6 ...   3   3   2]\n",
      " [  5   6   5 ...   3   4   3]\n",
      " ...\n",
      " [  5   5   3 ...   2   3   2]\n",
      " [  5   4   6 ...   2   4   3]\n",
      " [  4   4   6 ...   2   3   4]]\n",
      "715350 [6.623529411764705, 6.765625, 6.413861386138614, 7.208163265306123, 5.961728395061728, 5.125, 4.092307692307692, 5.191512513601741, 3.0878274268104775, 6.564154786150713, 6.244660194174758, 4.758695652173913, 5.317357512953368, 4.963636363636364, 5.827160493827161, 6.1210191082802545, 6.338983050847458, 5.403934426229508, 5.3328125, 6.080118694362018, 6.272588055130169, 5.906600249066003, 5.421530479896239, 4.736916548797737, 5.914407988587731, 5.3674911660777385, 5.571428571428571, 6.177914110429448, 6.132352941176471, 5.486005089058525, 5.763341067285383, 5.254830917874396, 5.508528784648187, 8.963414634146341, 5.969230769230769, 5.64248159831756, 5.209705372616984, 6.1122278056951425, 4.744154057771665, 6.025445292620865, 5.773858921161826, 5.267182130584192, 6.103896103896104, 4.659685863874346, 4.920388349514563, 3.968652037617555, 6.4816666666666665, 3.6742671009771986, 5.619402985074627, 5.150118203309693, 3.968186638388123, 4.6992481203007515, 5.267391304347826, 4.55678391959799, 6.019642857142857, 3.5987460815047023, 5.542619542619542, 5.861344537815126, 4.952205882352941, 4.1535087719298245, 5.876388888888889, 5.107262569832402, 5.859649122807017, 4.395696913002807, 5.192457737321196, 5.969387755102041, 5.709718670076726, 5.257261410788382, 5.640091116173121, 5.096006144393241, 4.15084388185654, 5.318975552968568, 5.74806800618238, 5.764851485148514, 5.878531073446328, 5.907730673316708, 5.911646586345381, 5.769140164899882, 5.586084905660377, 5.270175438596492, 6.022018348623853, 5.8649468892261005, 5.6938775510204085, 5.475258918296893, 5.857142857142857, 5.868817204301076, 5.808108108108108, 5.049543676662321, 5.160541586073501, 4.77038895859473, 5.712581344902386, 5.754662840746055, 5.9280868385345995, 4.301488833746898, 4.435897435897436, 5.059139784946237, 5.743697478991597, 5.773960216998192, 4.552331606217616, 5.789644012944984]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmovies = Get_MDCK_Movies_Paths()\\n\\nfor movie in movies:\\n    hdf5_file = movie + \"HDF/segmented.hdf5\"\\n    print (\"Calculating for {}\".format(hdf5_file))\\n    Local_Density_Nucleus_Size_Fluo_Signal(hdf5_file=hdf5_file).Append_To_HDF(local_density=True, nucleus_size=True)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the class:\n",
    "\n",
    "hdf5_file = \"/Volumes/lowegrp/Data/Kristina/Cells_MDCK/AB0124/pos7/HDF/segmented.hdf5\"\n",
    "call = Fluo_Signal_Intensity(hdf5_file=hdf5_file).Process_Whole_Movie()\n",
    "\n",
    "print (len(call), call[0:100])\n",
    "\n",
    "\"\"\"\n",
    "movies = Get_MDCK_Movies_Paths()\n",
    "\n",
    "for movie in movies:\n",
    "    hdf5_file = movie + \"HDF/segmented.hdf5\"\n",
    "    print (\"Calculating for {}\".format(hdf5_file))\n",
    "    Local_Density_Nucleus_Size_Fluo_Signal(hdf5_file=hdf5_file).Append_To_HDF(local_density=True, nucleus_size=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
